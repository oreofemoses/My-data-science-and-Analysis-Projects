{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "string  = tf.Variable(\"This is a string\", tf.string)## UpperCas 'V' for the variable\n",
    "number = tf.Variable(324, tf.int16)\n",
    "floating = tf.Variable(3.567, tf.float64)\n",
    "#all of this are tensors of shape 0 i.e a numpy array of shape 0 aka a scalar\n",
    "\n",
    "\n",
    "rank1_tensor = tf.Variable(['text'], tf.string)\n",
    "rank2_tensor = tf.Variable([['text'],['text2']], tf.string)\n",
    "## just as their names imply the ranks are respectively...\n",
    "## to determine the rank we canjust write:\n",
    "tf.rank(rank2_tensor)\n",
    "#Output: <tf.Tensor: shape=(), dtype=int32, numpy=2> \n",
    "\n",
    "# we can also get the shape of a tensor.\n",
    "rank2_tensor.shape\n",
    "# Output: TensorShape([2,1]) the first value represents the number of columns and the second represents the number of elements per column.\n",
    "\n",
    "#----- Changing Shape -----#\n",
    "tensor1 = tf.ones([1,2,3])\n",
    "tensor2 = tf.reshape(tensor1, [2,3,1])\n",
    "tensor3 = tf.reshape(tensor2, [3,-1])# by using -1 we allow tensor to calculate the suitable shape for us.\n",
    "\n",
    "#-----Types of tensor-----#\n",
    "# Variable, Constant, Placeholder, SparseTensor\n",
    "\n",
    "#-----Evaluating Tensors-----#\n",
    "# with tf.Session() as sess:\n",
    "#     tensor.eval()\n",
    "\n",
    "t = tf.zeros([5,5,5,5])\n",
    "t1 = tf.reshape(t, [25, -1])\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec147523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----Core learning  Algorithms-----#\n",
    "#Linear Regression\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib \n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf\n",
    "\n",
    "dftrain = pd.read_csv('train.csv')\n",
    "dfeval = pd.read_csv('eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n",
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique() ## gets all unique values in the column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype = tf.float32))\n",
    "    \n",
    "    \n",
    "##Now that we have our data ready i.e we've loaded the data and converted categorical data into numerical, we mive to the training process.\n",
    "##-----The training process-----##\n",
    "\n",
    "\n",
    "## we load the data in batches unto our ram.\n",
    "def make_input_fn(data_df, label_df, num_epochs = 10, shuffle = True, batch_size=32):\n",
    "    def input_function(): # inner funcy=tion, will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)# randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)#split dataset into patches and repeat for the number of epochs\n",
    "        return ds# batch the dataset\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs = 1, shuffle = False)\n",
    "\n",
    "#---- creating the model-----# \n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "\n",
    "#----Training the model-----#\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "clear_output()\n",
    "print(result['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774eab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(linear_est.predict(eval_input_fn))# get the predictions for every entry\n",
    "print(dfeval.loc[264])## get the details of the passenger\n",
    "#print(y_eval.loc[-1])## survived or not\n",
    "result[263]## percentage chance if survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the training and evaluation datasets from CSV files\n",
    "dftrain = pd.read_csv('Real estate.csv')\n",
    "dfeval = pd.read_csv('Realestate_eval.csv')\n",
    "\n",
    "# Separate the target variable from the feature variables\n",
    "y_train = dftrain.pop('house price of unit area')\n",
    "y_eval = dfeval.pop('house price of unit area')\n",
    "\n",
    "# Define a list of numeric feature columns for the model to use\n",
    "feature_columns = [tf.feature_column.numeric_column(feature_name, dtype=tf.float32)\n",
    "                   for feature_name in dftrain.columns]\n",
    "\n",
    "# Define a function to create a `tf.data.Dataset` object for training or evaluation\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "# Create input functions for training and evaluation datasets\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Create a linear regression model using the TensorFlow Estimator API\n",
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# Train the model using the training dataset\n",
    "linear_est.train(train_input_fn)\n",
    "\n",
    "# Evaluate the model using the evaluation dataset and print the accuracy score\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9df82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the respective numeric values\n",
      "SepalLength: 2.4\n",
      "SepalWidth: 2.6\n",
      "PetalLength: 6.5\n",
      "PetalWidth: 6.3\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\OREO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py:786: ClassificationOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\OREO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\multi_class_head.py:455: PredictOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\OREO\\AppData\\Local\\Temp\\tmp3330ks9y\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "prediction is \"Virginica\", (56.5%)\n"
     ]
    }
   ],
   "source": [
    "##----- Classification------#\n",
    "from IPython.display import clear_output\n",
    "# Import necessary libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "##----- loading our data -----##\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header = 0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header = 0)\n",
    "\n",
    "##----- Separating our target from features ----#\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "##--- Create feature columns ---##\n",
    "my_feature_columns = [tf.feature_column.numeric_column(key=key) for key in train.keys()]\n",
    "\n",
    "##---- Input Function ----#\n",
    "def input_fn(features, labels, training = True, batch_size = 256):\n",
    "    #Convert the input to a dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    #Shuffle and repeaat if you are in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "##----- Building the Model -----#\n",
    "## Using the DNNCLASSIFIER\n",
    "# build a DNN(deep neural network) with 2 hidden layers and with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns,\n",
    "    #two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units = [30,10],\n",
    "    #the model must choose between 3 classes.\n",
    "    n_classes = 3)\n",
    "\n",
    "##----- Training the model -----##\n",
    "classifier.train(\n",
    "input_fn = lambda: input_fn(train,  train_y, training = True), steps = 5000)\n",
    "\n",
    "##-----Evaluating the model ----##\n",
    "\n",
    "classifier.evaluate(\n",
    "input_fn = lambda: input_fn(test,  test_y, training = False))\n",
    "\n",
    "clear_output()\n",
    "##----- Predicting from input ----##\n",
    "def predict_input_fn(features, batch_size = 256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict= {}\n",
    "print(\"Please enter the respective numeric values\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + ': ')\n",
    "        if not val.isdigit(): valid = False\n",
    "    predict[feature] = [float(val)]\n",
    "    \n",
    "predictions = classifier.predict(input_fn = lambda:predict_input_fn(predict))\n",
    "for pred_dict in predictions\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('prediction is \"{}\", ({:.1f}%)'.format(SPECIES[class_id], 100*probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64e5212f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.        5.9999995 7.4999995 8.25      8.625     8.812501  8.90625  ]\n"
     ]
    }
   ],
   "source": [
    "##-----Clustering-----##\n",
    "##----Hidden Marcov Model-----##\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "##the probability distribution were working with is a weather prediction\n",
    "##the probability has already being defined as:\n",
    "#1. Cold days are encoded by 0 and hot by 1\n",
    "#2.The first day in our sequence has an 80% chance of being cold\n",
    "#3.A cold day has a 30% chance of being followed by a hot day\n",
    "#4.A hot day has a 20% chance of being followed by a cold day\n",
    "#5.On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and \n",
    "#mean and standard deviation 15 and 10 on a hot day.\n",
    "tfd = tfp.distributions\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2])\n",
    "transition_distribution = tfd.Categorical(probs = [[0.7,0.3],[0.2,0.8]])\n",
    "observation_distribution = tfd.Normal(loc = [0., 15.], scale = [5., 10.])\n",
    "# loc: mean and scale:standard deviation\n",
    "# the Model: \n",
    "model = tfd.HiddenMarkovModel(\n",
    "        initial_distribution=initial_distribution,\n",
    "        transition_distribution=transition_distribution,\n",
    "        observation_distribution=observation_distribution,\n",
    "        num_steps = 7)\n",
    "mean = model.mean()\n",
    "with tf.compat.v1.Session() as sess:# we need to do this to run a session.\n",
    "    print(mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f522ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7105a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
